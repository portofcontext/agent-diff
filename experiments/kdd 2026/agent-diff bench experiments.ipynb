{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install agent-diff langchain langchain-openai langchain-anthropic pandas matplotlib -q "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ca31907"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#AGENT_DIFF_API_KEY = \"\"\n",
        "#AGENT_DIFF_BASE_URL = \"https://api.agentdiff.dev\"\n",
        "OPENAI_API_KEY = \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Docs not found: ../../examples/linear/testsuites/linear_docs/linear_api_full_docs.json\n",
            "[OK] Slack docs: 27 endpoints\n",
            "[OK] Box docs: 26 endpoints\n",
            "[OK] Calendar docs: 37 endpoints\n",
            "[MISSING] Linear docs: 0 endpoints\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# Base path relative to this notebook\n",
        "DOCS_BASE = Path(\"../../examples\")\n",
        "\n",
        "def load_api_docs(filepath: Path) -> dict:\n",
        "    \"\"\"Load API docs JSON, return empty dict if not found.\"\"\"\n",
        "    if filepath.exists():\n",
        "        return json.load(open(filepath))\n",
        "    print(f\"Docs not found: {filepath}\")\n",
        "    return {}\n",
        "\n",
        "def format_docs_markdown(docs: dict) -> str:\n",
        "    \"\"\"Convert API docs dict to markdown format.\"\"\"\n",
        "    if not docs:\n",
        "        return \"\"\n",
        "    \n",
        "    markdown = \"\"\n",
        "    for endpoint, info in docs.items():\n",
        "        markdown += f\"## {endpoint}\\n\"\n",
        "        markdown += f\"{info.get('description', '')}\\n\\n\"\n",
        "        \n",
        "        if info.get('parameters'):\n",
        "            markdown += \"**Parameters:**\\n\"\n",
        "            for location, params in info['parameters'].items():\n",
        "                markdown += f\"  {location}:\\n\"\n",
        "                if not isinstance(params, dict):\n",
        "                    markdown += f\"    {params}\\n\"\n",
        "                    continue\n",
        "                for param_name, param_info in params.items():\n",
        "                    # Handle case where param_info might be a string\n",
        "                    if not isinstance(param_info, dict):\n",
        "                        markdown += f\"    - `{param_name}`: {param_info}\\n\"\n",
        "                        continue\n",
        "                    required = \"**required**\" if param_info.get('required') else \"optional\"\n",
        "                    param_type = param_info.get('type', 'any')\n",
        "                    param_desc = param_info.get('description', '')\n",
        "                    markdown += f\"    - `{param_name}` ({param_type}, {required}): {param_desc}\\n\"\n",
        "            markdown += \"\\n\"\n",
        "    \n",
        "    return markdown\n",
        "\n",
        "# Load available docs (all services)\n",
        "slack_docs = load_api_docs(DOCS_BASE / \"slack/testsuites/slack_docs/slack_api_full_docs.json\")\n",
        "box_docs = load_api_docs(DOCS_BASE / \"box/testsuites/box_docs/box_api_full_docs.json\")\n",
        "calendar_docs = load_api_docs(DOCS_BASE / \"calendar/testsuites/calendar_docs/calendar_api_full_docs.json\")\n",
        "linear_docs = load_api_docs(DOCS_BASE / \"linear/testsuites/linear_docs/linear_api_full_docs.json\")\n",
        "\n",
        "# Format to markdown\n",
        "slack_docs_markdown = format_docs_markdown(slack_docs)\n",
        "box_docs_markdown = format_docs_markdown(box_docs)\n",
        "calendar_docs_markdown = format_docs_markdown(calendar_docs)\n",
        "linear_docs_markdown = format_docs_markdown(linear_docs)\n",
        "\n",
        "# Summary\n",
        "print(f\"[{'OK' if slack_docs else 'MISSING'}] Slack docs: {len(slack_docs)} endpoints\")\n",
        "print(f\"[{'OK' if box_docs else 'MISSING'}] Box docs: {len(box_docs)} endpoints\")\n",
        "print(f\"[{'OK' if calendar_docs else 'MISSING'}] Calendar docs: {len(calendar_docs)} endpoints\")\n",
        "print(f\"[{'OK' if linear_docs else 'MISSING'}] Linear docs: {len(linear_docs)} endpoints\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from typing import Optional, Tuple\n",
        "\n",
        "# Service configurations with base URLs\n",
        "SERVICE_CONFIG = {\n",
        "    \"slack\": {\n",
        "        \"name\": \"Slack\",\n",
        "        \"base_url\": \"https://slack.com/api\",\n",
        "        \"description\": \"Slack workspace messaging and collaboration API\",\n",
        "    },\n",
        "    \"box\": {\n",
        "        \"name\": \"Box\",\n",
        "        \"base_url\": \"https://api.box.com/2.0\",\n",
        "        \"description\": \"Box cloud storage and file management API\",\n",
        "    },\n",
        "    \"calendar\": {\n",
        "        \"name\": \"Google Calendar\",\n",
        "        \"base_url\": \"https://www.googleapis.com/calendar/v3\",\n",
        "        \"description\": \"Google Calendar scheduling and events API\",\n",
        "    },\n",
        "    \"linear\": {\n",
        "        \"name\": \"Linear\",\n",
        "        \"base_url\": \"https://api.linear.app/graphql\",\n",
        "        \"description\": \"Linear project management and issue tracking API\",\n",
        "    },\n",
        "}\n",
        "\n",
        "# ReAct System Prompt \n",
        "REACT_SYSTEM_PROMPT_WITH_API_DOCS = \"\"\"You are an AI assistant that completes tasks by interacting with APIs via bash commands.\n",
        "\n",
        "## Current Session\n",
        "- **Service**: {service_name}\n",
        "- **Base URL**: {base_url}\n",
        "- **Description**: {service_description}\n",
        "\n",
        "## Environment\n",
        "- You are authenticated as a user in the {service_name} workspace/account.\n",
        "- Authentication is handled automatically via proxy. Use placeholder tokens like `<TOKEN>` where credentials would go.\n",
        "- You execute bash commands (primarily curl) to interact with the {service_name} API.\n",
        "- The environment is stateless between commands - you cannot install packages or persist files.\n",
        "\n",
        "## Response Format\n",
        "You must respond using XML tags. Think step-by-step, then execute a command OR declare completion.\n",
        "\n",
        "**To execute a bash command:**\n",
        "<thinking>\n",
        "Your reasoning about what needs to be done and why this command will help.\n",
        "</thinking>\n",
        "\n",
        "<action>\n",
        "Your bash command here (e.g., curl request)\n",
        "</action>\n",
        "\n",
        "**When the task is complete:**\n",
        "<thinking>\n",
        "Your reasoning confirming the task is done based on API responses.\n",
        "</thinking>\n",
        "\n",
        "<done>\n",
        "Brief summary of what was accomplished.\n",
        "</done>\n",
        "\n",
        "## Rules\n",
        "1. Execute ONE command at a time, then wait for the result.\n",
        "2. Parse API responses carefully - extract IDs and data needed for subsequent calls.\n",
        "3. If a command fails, analyze the error and try a different approach.\n",
        "4. Only use <done> when the task is fully completed (not just when you've gathered information).\n",
        "\n",
        "## API Documentation\n",
        "{api_docs}\n",
        "\"\"\"\n",
        "\n",
        "REACT_SYSTEM_PROMPT = \"\"\"You are an AI assistant that completes tasks by interacting with APIs via bash commands.\n",
        "\n",
        "## Current Session\n",
        "- **Service**: {service_name}\n",
        "- **Base URL**: {base_url}\n",
        "- **Description**: {service_description}\n",
        "\n",
        "## Environment\n",
        "- You are authenticated as a user in the {service_name} workspace/account.\n",
        "- Authentication is handled automatically via proxy. Use placeholder tokens like `<TOKEN>` where credentials would go.\n",
        "- You execute bash commands (primarily curl) to interact with the {service_name} API.\n",
        "- If you are not sure how to use {service_name} API, explore the endpoint, parameters, and learn how it works.\n",
        "- The environment is stateless between commands - you cannot install packages or persist files.\n",
        "\n",
        "## Response Format\n",
        "You must respond using XML tags. Think step-by-step, then execute a command OR declare completion.\n",
        "\n",
        "**To execute a bash command:**\n",
        "<thinking>\n",
        "Your reasoning about what needs to be done and why this command will help.\n",
        "</thinking>\n",
        "\n",
        "<action>\n",
        "Your bash command here (e.g., curl request)\n",
        "</action>\n",
        "\n",
        "**When the task is complete:**\n",
        "<thinking>\n",
        "Your reasoning confirming the task is done based on API responses.\n",
        "</thinking>\n",
        "\n",
        "<done>\n",
        "Brief summary of what was accomplished.\n",
        "</done>\n",
        "\n",
        "## Rules\n",
        "1. Execute ONE command at a time, then wait for the result.\n",
        "2. Parse API responses carefully - extract IDs and data needed for subsequent calls.\n",
        "3. If a command fails, analyze the error and try a different approach.\n",
        "4. Only use <done> when the task is fully completed (not just when you've gathered information).\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Function to build the full system prompt\n",
        "def build_system_prompt(service: str, docs_markdown: str, include_api_docs: bool = True) -> str:\n",
        "    \"\"\"Build system prompt with service-specific context.\n",
        "    \n",
        "    Args:\n",
        "        service: Service name (slack, box, calendar, linear)\n",
        "        docs_markdown: Formatted API documentation markdown\n",
        "        include_api_docs: Whether to include API docs in the prompt\n",
        "    \n",
        "    Returns:\n",
        "        str: Complete system prompt\n",
        "    \"\"\"\n",
        "    config = SERVICE_CONFIG.get(service.lower(), {\n",
        "        \"name\": service,\n",
        "        \"base_url\": \"unknown\",\n",
        "        \"description\": f\"{service} API\",\n",
        "    })\n",
        "    \n",
        "    if include_api_docs:\n",
        "        return REACT_SYSTEM_PROMPT_WITH_API_DOCS.format(\n",
        "            service_name=config[\"name\"],\n",
        "            base_url=config[\"base_url\"],\n",
        "            service_description=config[\"description\"],\n",
        "            api_docs=docs_markdown,\n",
        "        )\n",
        "    else:\n",
        "        return REACT_SYSTEM_PROMPT.format(\n",
        "            service_name=config[\"name\"],\n",
        "            base_url=config[\"base_url\"],\n",
        "            service_description=config[\"description\"],\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "def parse_react_response(response: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:\n",
        "    \"\"\"\n",
        "    Parse ReAct XML response.\n",
        "    Returns: (thinking, action, done)\n",
        "    - If action is present: execute the command\n",
        "    - If done is present: task is complete\n",
        "    \"\"\"\n",
        "    thinking_match = re.search(r'<thinking>(.*?)</thinking>', response, re.DOTALL)\n",
        "    action_match = re.search(r'<action>(.*?)</action>', response, re.DOTALL)\n",
        "    done_match = re.search(r'<done>(.*?)</done>', response, re.DOTALL)\n",
        "    \n",
        "    thinking = thinking_match.group(1).strip() if thinking_match else None\n",
        "    action = action_match.group(1).strip() if action_match else None\n",
        "    done = done_match.group(1).strip() if done_match else None\n",
        "    \n",
        "    return thinking, action, done\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "25917f7e"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import time\n",
        "import httpx\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Any, List, Dict\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from agent_diff import (\n",
        "    AgentDiff,\n",
        "    BashExecutorProxy,\n",
        ")\n",
        "\n",
        "# ============ Benchmark Configurations ============\n",
        "\n",
        "BENCHMARK_CONFIGS = {\n",
        "    \"slack\": {\n",
        "        \"test_suite_name\": \"Slack Bench v2\",\n",
        "        \"docs_markdown\": slack_docs_markdown,\n",
        "    },\n",
        "    \"box\": {\n",
        "        \"test_suite_name\": \"Box Bench v2\",\n",
        "        \"docs_markdown\": box_docs_markdown,\n",
        "    },\n",
        "    \"calendar\": {\n",
        "        \"test_suite_name\": \"Calendar Bench\",\n",
        "        \"docs_markdown\": calendar_docs_markdown,\n",
        "    },\n",
        "    \"linear\": {\n",
        "        \"test_suite_name\": \"Linear Bench\",\n",
        "        \"docs_markdown\": linear_docs_markdown,\n",
        "    },\n",
        "}\n",
        "\n",
        "def get_benchmark_config(service: str, include_api_docs: bool = True) -> dict:\n",
        "    \"\"\"Get benchmark configuration for a service.\n",
        "    \n",
        "    Args:\n",
        "        service: Service name\n",
        "        include_api_docs: Whether to include API docs in the system prompt\n",
        "    \"\"\"\n",
        "    service_lower = service.lower()\n",
        "    if service_lower not in BENCHMARK_CONFIGS:\n",
        "        raise ValueError(f\"Unknown service: {service}. Available: {list(BENCHMARK_CONFIGS.keys())}\")\n",
        "    \n",
        "    config = BENCHMARK_CONFIGS[service_lower]\n",
        "    return {\n",
        "        \"service\": service_lower,\n",
        "        \"test_suite_name\": config[\"test_suite_name\"],\n",
        "        \"docs_markdown\": config[\"docs_markdown\"],\n",
        "        \"include_api_docs\": include_api_docs,\n",
        "        \"system_prompt\": build_system_prompt(service_lower, config[\"docs_markdown\"], include_api_docs),\n",
        "    }\n",
        "\n",
        "# ============ Output Directory ============\n",
        "\n",
        "OUTPUT_DIR = Path(\"evaluation_outputs\")\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# ============  ReAct Agent ============\n",
        "\n",
        "def call_openrouter(\n",
        "    model: str,\n",
        "    messages: List[Dict],\n",
        "    api_key: str,\n",
        ") -> Dict:\n",
        "    \"\"\"Make a completion request to OpenRouter API (no tool calling).\n",
        "    \n",
        "    Returns:\n",
        "        dict: {\n",
        "            \"content\": str,           # Model response text\n",
        "            \"finish_reason\": str,     # \"stop\", \"length\", etc.\n",
        "            \"usage\": {\n",
        "                \"prompt_tokens\": int,\n",
        "                \"completion_tokens\": int,\n",
        "                \"total_tokens\": int,\n",
        "                \"cost\": float,        # USD cost\n",
        "            }\n",
        "        }\n",
        "    \"\"\"\n",
        "    with httpx.Client(timeout=120) as client:\n",
        "        response = client.post(\n",
        "            \"https://openrouter.ai/api/v1/chat/completions\",\n",
        "            headers={\n",
        "                \"Authorization\": f\"Bearer {api_key}\",\n",
        "                \"Content-Type\": \"application/json\",\n",
        "            },\n",
        "            json={\n",
        "                \"model\": model,\n",
        "                \"messages\": messages,\n",
        "            },\n",
        "        )\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "        \n",
        "        choice = data[\"choices\"][0]\n",
        "        usage = data.get(\"usage\", {})\n",
        "        \n",
        "        return {\n",
        "            \"content\": choice[\"message\"][\"content\"],\n",
        "            \"finish_reason\": choice.get(\"finish_reason\"),\n",
        "            \"usage\": {\n",
        "                \"prompt_tokens\": usage.get(\"prompt_tokens\", 0),\n",
        "                \"completion_tokens\": usage.get(\"completion_tokens\", 0),\n",
        "                \"total_tokens\": usage.get(\"total_tokens\", 0),\n",
        "                \"cost\": usage.get(\"cost\", 0.0),\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "def run_react_agent(\n",
        "    model_name: str,\n",
        "    task_prompt: str,\n",
        "    bash_executor: BashExecutorProxy,\n",
        "    system_prompt: str,\n",
        "    max_iterations: int = 25,\n",
        "    trace_accumulator: Dict = None,\n",
        "    stop_event: \"threading.Event\" = None,\n",
        ") -> Dict:\n",
        "    \"\"\"\n",
        "    Custom ReAct agent loop using XML tags.\n",
        "    Returns structured trace with each step containing thinking, action, observation,\n",
        "    plus token usage and finish reasons.\n",
        "    \n",
        "    If trace_accumulator is provided, steps are written to it in real-time,\n",
        "    allowing partial trace recovery on timeout.\n",
        "    \n",
        "    If stop_event is provided and set, the loop exits gracefully at the next iteration.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": f\"Task: {task_prompt}\"},\n",
        "    ]\n",
        "    \n",
        "    # Use provided accumulator or create new one\n",
        "    if trace_accumulator is not None:\n",
        "        steps = trace_accumulator.setdefault(\"steps\", [])\n",
        "        trace_accumulator[\"final\"] = None\n",
        "        trace_accumulator[\"completed\"] = False\n",
        "        trace_accumulator[\"usage\"] = {\"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0, \"cost\": 0.0}\n",
        "    else:\n",
        "        steps = []\n",
        "    \n",
        "    final_step = None\n",
        "    completed = False\n",
        "    \n",
        "    # Track total usage across all iterations\n",
        "    total_usage = {\n",
        "        \"prompt_tokens\": 0,\n",
        "        \"completion_tokens\": 0,\n",
        "        \"total_tokens\": 0,\n",
        "        \"cost\": 0.0,\n",
        "    }\n",
        "    \n",
        "    for iteration in range(max_iterations):\n",
        "        # Check stop signal at start of each iteration\n",
        "        if stop_event and stop_event.is_set():\n",
        "            # Timeout was triggered - exit gracefully\n",
        "            break\n",
        "        \n",
        "        # Get model response\n",
        "        try:\n",
        "            api_response = call_openrouter(\n",
        "                model=model_name,\n",
        "                messages=messages,\n",
        "                api_key=OPENAI_API_KEY,\n",
        "            )\n",
        "            response_text = api_response[\"content\"]\n",
        "            finish_reason = api_response[\"finish_reason\"]\n",
        "            iter_usage = api_response[\"usage\"]\n",
        "            \n",
        "            # Accumulate total usage\n",
        "            total_usage[\"prompt_tokens\"] += iter_usage[\"prompt_tokens\"]\n",
        "            total_usage[\"completion_tokens\"] += iter_usage[\"completion_tokens\"]\n",
        "            total_usage[\"total_tokens\"] += iter_usage[\"total_tokens\"]\n",
        "            total_usage[\"cost\"] += iter_usage[\"cost\"]\n",
        "            \n",
        "            # Update accumulator in real-time\n",
        "            if trace_accumulator is not None:\n",
        "                trace_accumulator[\"usage\"] = total_usage.copy()\n",
        "                \n",
        "        except Exception as e:\n",
        "            steps.append({\n",
        "                \"iteration\": iteration + 1,\n",
        "                \"error\": f\"API error: {str(e)}\",\n",
        "            })\n",
        "            break\n",
        "        \n",
        "        # Parse XML response\n",
        "        thinking, action, done = parse_react_response(response_text)\n",
        "        \n",
        "        # If model includes both, execute the action and ignore premature done\n",
        "        if action:\n",
        "            # Execute bash command\n",
        "            try:\n",
        "                result = bash_executor.execute(action)\n",
        "                # Normalize result to dict for consistent storage\n",
        "                if isinstance(result, dict):\n",
        "                    observation = {\n",
        "                        \"stdout\": result.get(\"stdout\", \"\"),\n",
        "                        \"stderr\": result.get(\"stderr\", \"\"),\n",
        "                        \"exit_code\": result.get(\"exit_code\", 0),\n",
        "                    }\n",
        "                else:\n",
        "                    observation = {\n",
        "                        \"stdout\": str(result) if result else \"\",\n",
        "                        \"stderr\": \"\",\n",
        "                        \"exit_code\": 0,\n",
        "                    }\n",
        "            except Exception as e:\n",
        "                observation = {\n",
        "                    \"stdout\": \"\",\n",
        "                    \"stderr\": str(e),\n",
        "                    \"exit_code\": 1,\n",
        "                    \"error\": str(e),\n",
        "                }\n",
        "            \n",
        "            # Record this step with nested structure + usage\n",
        "            steps.append({\n",
        "                \"iteration\": iteration + 1,\n",
        "                \"thinking\": thinking,\n",
        "                \"action\": action,\n",
        "                \"observation\": observation,\n",
        "                \"raw_response\": response_text,\n",
        "                \"finish_reason\": finish_reason,\n",
        "                \"usage\": iter_usage,\n",
        "            })\n",
        "            \n",
        "            # Format observation for model (just stdout, or error info)\n",
        "            if observation.get(\"exit_code\", 0) != 0:\n",
        "                obs_text = f\"{observation['stdout']}\\n[stderr]: {observation['stderr']}\\n[exit_code]: {observation['exit_code']}\".strip()\n",
        "            else:\n",
        "                obs_text = observation[\"stdout\"].strip() if observation[\"stdout\"] else \"(empty output)\"\n",
        "            \n",
        "            # Add to conversation\n",
        "            messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
        "            messages.append({\"role\": \"user\", \"content\": f\"<observation>\\n{obs_text}\\n</observation>\"})\n",
        "        elif done:\n",
        "            # Task completed (only when NO action present)\n",
        "            final_step = {\n",
        "                \"iteration\": iteration + 1,\n",
        "                \"thinking\": thinking,\n",
        "                \"summary\": done,\n",
        "                \"raw_response\": response_text,\n",
        "                \"finish_reason\": finish_reason,\n",
        "                \"usage\": iter_usage,\n",
        "            }\n",
        "            completed = True\n",
        "            break\n",
        "        else:\n",
        "            # No action and no done - malformed response\n",
        "            steps.append({\n",
        "                \"iteration\": iteration + 1,\n",
        "                \"thinking\": thinking,\n",
        "                \"warning\": \"No <action> or <done> tag found\",\n",
        "                \"raw_response\": response_text,\n",
        "                \"finish_reason\": finish_reason,\n",
        "                \"usage\": iter_usage,\n",
        "            })\n",
        "            messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
        "            messages.append({\"role\": \"user\", \"content\": \"Please respond with either an <action> to execute or <done> if the task is complete.\"})\n",
        "    \n",
        "    result = {\n",
        "        \"steps\": steps,\n",
        "        \"final\": final_step,\n",
        "        \"iterations\": iteration + 1,\n",
        "        \"completed\": completed,\n",
        "        \"usage\": total_usage,\n",
        "    }\n",
        "    \n",
        "    # Update accumulator if provided (for timeout recovery)\n",
        "    if trace_accumulator is not None:\n",
        "        trace_accumulator[\"final\"] = final_step\n",
        "        trace_accumulator[\"iterations\"] = iteration + 1\n",
        "        trace_accumulator[\"completed\"] = completed\n",
        "        trace_accumulator[\"usage\"] = total_usage\n",
        "    \n",
        "    return result\n",
        "\n",
        "\n",
        "async def run_single_test(\n",
        "    client: AgentDiff, \n",
        "    model_name: str, \n",
        "    test: Any, \n",
        "    system_prompt: str,\n",
        "    test_timeout_seconds: int = 300,\n",
        "    max_iterations: int = 25,\n",
        ") -> tuple:\n",
        "    \"\"\"Run a single test case using custom ReAct agent.\n",
        "    \n",
        "    Args:\n",
        "        client: AgentDiff client instance\n",
        "        model_name: Model identifier (e.g., 'openai/gpt-5-mini')\n",
        "        test: Test object with id and prompt attributes\n",
        "        system_prompt: Full system prompt including API docs\n",
        "        test_timeout_seconds: Max seconds before timeout\n",
        "        max_iterations: Max ReAct loop iterations\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (test_id, result_dict) where result_dict contains:\n",
        "            - prompt (str): Task prompt\n",
        "            - status (str): 'passed', 'failed', 'timeout', or 'error'\n",
        "            - passed (bool): Whether assertions passed\n",
        "            - score (float): Score 0-100\n",
        "            - time (float): Execution seconds\n",
        "            - failures (list[str]): Failure messages\n",
        "            - runId (str): Run UUID\n",
        "            - error (str|None): Error message if status='error'\n",
        "            - trace (dict): Execution trace containing:\n",
        "                - steps (list): Each step has iteration, thinking, action, \n",
        "                  observation, raw_response, finish_reason, usage\n",
        "                - final (dict|None): Completion step with usage\n",
        "                - iterations (int): Total iterations\n",
        "                - completed (bool): Whether agent declared done\n",
        "                - usage (dict): Total {prompt_tokens, completion_tokens, \n",
        "                  total_tokens, cost}\n",
        "            - diff (dict|None): State changes {inserts, updates, deletes}\n",
        "    \"\"\"\n",
        "    import threading\n",
        "    \n",
        "    test_id = test.id\n",
        "    prompt = test.prompt\n",
        "    response = None\n",
        "    timed_out = False\n",
        "    env = None\n",
        "    stop_event = threading.Event()  # Signal for graceful thread cancellation\n",
        "\n",
        "    try:\n",
        "        # Initialize environment\n",
        "        env = client.init_env(testId=test_id)\n",
        "        run = client.start_run(envId=env.environmentId, testId=test_id)\n",
        "\n",
        "        # Create bash executor (direct, not LangChain tool)\n",
        "        bash_executor = BashExecutorProxy(\n",
        "            env.environmentId,\n",
        "            base_url=client.base_url,\n",
        "            api_key=client.api_key,\n",
        "        )\n",
        "\n",
        "        # Execution with timeout\n",
        "        # Use trace_accumulator to capture partial trace on timeout\n",
        "        trace_accumulator = {\n",
        "            \"steps\": [], \n",
        "            \"final\": None, \n",
        "            \"completed\": False,\n",
        "            \"usage\": {\"prompt_tokens\": 0, \"completion_tokens\": 0, \"total_tokens\": 0, \"cost\": 0.0},\n",
        "        }\n",
        "        \n",
        "        start = time.perf_counter()\n",
        "        try:\n",
        "            response = await asyncio.wait_for(\n",
        "                asyncio.to_thread(\n",
        "                    run_react_agent,\n",
        "                    model_name=model_name,\n",
        "                    task_prompt=prompt,\n",
        "                    bash_executor=bash_executor,\n",
        "                    system_prompt=system_prompt,\n",
        "                    max_iterations=max_iterations,\n",
        "                    trace_accumulator=trace_accumulator,\n",
        "                    stop_event=stop_event,\n",
        "                ),\n",
        "                timeout=test_timeout_seconds\n",
        "            )\n",
        "        except asyncio.TimeoutError:\n",
        "            timed_out = True\n",
        "            # Signal thread to stop at next iteration\n",
        "            stop_event.set()\n",
        "            # Give thread a moment to finish current operation and exit\n",
        "            await asyncio.sleep(2)\n",
        "            # Use accumulated trace (partial) instead of losing it\n",
        "            response = {\n",
        "                \"steps\": trace_accumulator.get(\"steps\", []),\n",
        "                \"final\": trace_accumulator.get(\"final\"),\n",
        "                \"iterations\": len(trace_accumulator.get(\"steps\", [])),\n",
        "                \"completed\": False,\n",
        "                \"usage\": trace_accumulator.get(\"usage\", {}),\n",
        "                \"timeout_error\": f\"Test timed out after {test_timeout_seconds} seconds\",\n",
        "            }\n",
        "        except Exception as e:\n",
        "            response = {\n",
        "                \"steps\": trace_accumulator.get(\"steps\", []),\n",
        "                \"final\": trace_accumulator.get(\"final\"),\n",
        "                \"iterations\": len(trace_accumulator.get(\"steps\", [])),\n",
        "                \"completed\": False,\n",
        "                \"usage\": trace_accumulator.get(\"usage\", {}),\n",
        "                \"error\": str(e),\n",
        "            }\n",
        "        finally:\n",
        "            execution_time = time.perf_counter() - start\n",
        "\n",
        "        # Evaluation\n",
        "        score = client.evaluate_run(runId=run.runId)\n",
        "        run_result = client.get_results_for_run(runId=run.runId)\n",
        "\n",
        "        result = {\n",
        "            \"prompt\": prompt,\n",
        "            \"status\": \"timeout\" if timed_out else run_result.status,\n",
        "            \"passed\": False if timed_out else run_result.passed,\n",
        "            \"score\": 0 if timed_out else run_result.score.get(\"percent\", 0),\n",
        "            \"time\": round(execution_time, 2),\n",
        "            \"failures\": [\"Test timed out\"] if timed_out else run_result.failures,\n",
        "            \"runId\": run.runId,\n",
        "            \"trace\": response,\n",
        "            \"diff\": getattr(run_result, \"diff\", None),\n",
        "        }\n",
        "\n",
        "        # Cleanup\n",
        "        client.delete_env(envId=env.environmentId)\n",
        "        return test_id, result\n",
        "\n",
        "    except Exception as e:\n",
        "        # Cleanup on error if environment was created\n",
        "        if env:\n",
        "            try:\n",
        "                client.delete_env(envId=env.environmentId)\n",
        "            except:\n",
        "                pass\n",
        "        return test_id, {\"passed\": False, \"score\": 0, \"status\": \"error\", \"error\": str(e)}\n",
        "\n",
        "\n",
        "async def run_benchmark_suite(\n",
        "    service: str,\n",
        "    models: list,\n",
        "    runs_per_test: int = 1,\n",
        "    max_tests: int = None,\n",
        "    max_concurrent_models: int = 1,\n",
        "    max_concurrent_tests: int = 10,\n",
        "    max_calls_per_minute: int = 90,\n",
        "    test_timeout_seconds: int = 300,\n",
        "    max_iterations: int = 25,\n",
        "    include_api_docs: bool = True,\n",
        "    checkpoint: \"BenchmarkCheckpoint\" = None,\n",
        "):\n",
        "    \"\"\"Run benchmark for a single service.\n",
        "    \n",
        "    Args:\n",
        "        service: Service to benchmark ('slack', 'box', 'calendar', 'linear')\n",
        "        models: List of model identifiers to evaluate\n",
        "        runs_per_test: Number of times to run each test\n",
        "        max_tests: Maximum number of tests to run (None = all)\n",
        "        max_concurrent_models: Max parallel model evaluations\n",
        "        max_concurrent_tests: Max parallel test executions\n",
        "        max_calls_per_minute: Rate limit for API calls\n",
        "        test_timeout_seconds: Timeout per test in seconds\n",
        "        max_iterations: Max ReAct iterations per test\n",
        "        include_api_docs: Whether to include API documentation in system prompt\n",
        "        checkpoint: Optional BenchmarkCheckpoint for resuming interrupted runs.\n",
        "                   If provided, skips already-completed tasks and saves progress incrementally.\n",
        "    \n",
        "    Returns:\n",
        "        List[dict]: List of result dicts, each containing:\n",
        "            - prompt (str): The task prompt\n",
        "            - status (str): 'passed', 'failed', 'timeout', or 'error'\n",
        "            - passed (bool): Whether the test passed\n",
        "            - score (float): Score percentage (0-100)\n",
        "            - time (float): Execution time in seconds\n",
        "            - failures (list): List of failure messages\n",
        "            - runId (str): Unique run identifier\n",
        "            - error (str|None): Error message if status='error'\n",
        "            - model (str): Model identifier used\n",
        "            - test_id (str): Test UUID (deterministic, constant across runs)\n",
        "            - test_name (str): Human-readable test name from benchmark suite\n",
        "            - service (str): Service name (e.g., 'slack', 'box')\n",
        "            - test_suite_name (str): Full test suite name (e.g., 'Slack Bench v2')\n",
        "            - include_api_docs (bool): Whether API docs were included in prompt\n",
        "            - timestamp (str): ISO format timestamp when test was run\n",
        "            - trace (dict): Execution trace containing:\n",
        "                - steps (list): List of ReAct steps, each with:\n",
        "                    - iteration (int)\n",
        "                    - thinking (str): Model's reasoning\n",
        "                    - action (str): Bash command executed\n",
        "                    - observation (dict): {stdout, stderr, exit_code}\n",
        "                    - raw_response (str): Full model response\n",
        "                    - finish_reason (str): \"stop\", \"length\" (context overflow), etc.\n",
        "                    - usage (dict): {prompt_tokens, completion_tokens, total_tokens, cost}\n",
        "                - final (dict|None): Completion step with thinking, summary, usage\n",
        "                - iterations (int): Total iterations\n",
        "                - completed (bool): Whether agent declared done\n",
        "                - usage (dict): Total tokens/cost for entire run:\n",
        "                    {prompt_tokens, completion_tokens, total_tokens, cost}\n",
        "            - diff (dict|None): State diff with inserts, updates, deletes\n",
        "    \"\"\"\n",
        "    # Get benchmark configuration for this service\n",
        "    config = get_benchmark_config(service, include_api_docs=include_api_docs)\n",
        "    test_suite_name = config[\"test_suite_name\"]\n",
        "    system_prompt = config[\"system_prompt\"]\n",
        "    run_timestamp = datetime.now().isoformat()\n",
        "    \n",
        "    client = AgentDiff(\n",
        "        #api_key=AGENT_DIFF_API_KEY,\n",
        "        #base_url=AGENT_DIFF_BASE_URL,\n",
        "    )\n",
        "    try:\n",
        "        suite_list = client.list_test_suites(name=test_suite_name)\n",
        "        if not suite_list.testSuites:\n",
        "            print(f\"[ERROR] Test suite '{test_suite_name}' not found on AgentDiff server.\")\n",
        "            return []\n",
        "\n",
        "        suite = client.get_test_suite(suite_list.testSuites[0].id, expand=True)\n",
        "        tests = suite.tests[:max_tests] if max_tests else suite.tests\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Error connecting to AgentDiff: {e}\")\n",
        "        return []\n",
        "\n",
        "    total_logical = len(tests) * len(models)\n",
        "    total_runs = total_logical * runs_per_test\n",
        "    \n",
        "    # Checkpointing: determine which tasks need to run\n",
        "    if checkpoint:\n",
        "        # Build list of all tasks, filter out completed ones\n",
        "        all_tasks_spec = []\n",
        "        for model in models:\n",
        "            for test in tests:\n",
        "                test_id = str(test.id)\n",
        "                for run_idx in range(runs_per_test):\n",
        "                    if not checkpoint.is_completed(model, test_id, run_idx):\n",
        "                        all_tasks_spec.append((model, test, run_idx))\n",
        "        \n",
        "        skipped = total_runs - len(all_tasks_spec)\n",
        "        if skipped > 0:\n",
        "            print(f\"\\n[{config['service'].upper()}] {test_suite_name} | {len(tests)} tests x {len(models)} models x {runs_per_test} runs\")\n",
        "            print(f\"[CHECKPOINT] Skipping {skipped} already completed, {len(all_tasks_spec)} remaining\")\n",
        "        else:\n",
        "            print(f\"\\n[{config['service'].upper()}] {test_suite_name} | {len(tests)} tests x {len(models)} models x {runs_per_test} runs = {total_runs} total\")\n",
        "        \n",
        "        # Use checkpoint's lock for thread safety\n",
        "        checkpoint_lock = asyncio.Lock()\n",
        "    else:\n",
        "        # No checkpoint - run all tasks\n",
        "        all_tasks_spec = [(model, test, run_idx) \n",
        "                         for model in models \n",
        "                         for test in tests \n",
        "                         for run_idx in range(runs_per_test)]\n",
        "        checkpoint_lock = None\n",
        "        print(f\"\\n[{config['service'].upper()}] {test_suite_name} | {len(tests)} tests x {len(models)} models x {runs_per_test} runs = {total_runs} total\")\n",
        "\n",
        "    semaphore = asyncio.Semaphore(max_concurrent_models * max_concurrent_tests)\n",
        "\n",
        "    # rate limiting state (per minute window)\n",
        "    window_seconds = 60\n",
        "    window_start = time.monotonic()\n",
        "    calls_in_window = 0\n",
        "    rate_lock = asyncio.Lock()\n",
        "\n",
        "    async def acquire_rate_slot():\n",
        "        nonlocal window_start, calls_in_window\n",
        "        while True:\n",
        "            async with rate_lock:\n",
        "                now = time.monotonic()\n",
        "                # reset window if needed\n",
        "                if now - window_start >= window_seconds:\n",
        "                    window_start = now\n",
        "                    calls_in_window = 0\n",
        "\n",
        "                if calls_in_window < max_calls_per_minute:\n",
        "                    calls_in_window += 1\n",
        "                    return  # allowed to proceed\n",
        "\n",
        "                # need to wait until current window ends\n",
        "                sleep_for = window_seconds - (now - window_start)\n",
        "            # sleep outside the lock\n",
        "            if sleep_for > 0:\n",
        "                await asyncio.sleep(sleep_for)\n",
        "\n",
        "    # Progress tracking state\n",
        "    completed_results = []\n",
        "    results_lock = asyncio.Lock()\n",
        "    \n",
        "    # Create progress bar with model names\n",
        "    model_names = [m.split(\"/\")[-1][:12] for m in models]\n",
        "    initial_desc = f\"{config['service'].upper()} | \" + \" | \".join(f\"{m}: 0/0\" for m in model_names)\n",
        "    \n",
        "    # Progress bar shows remaining tasks (may be less than total if resuming)\n",
        "    tasks_to_run = len(all_tasks_spec)\n",
        "    pbar = tqdm(\n",
        "        total=tasks_to_run,\n",
        "        desc=initial_desc,\n",
        "        unit=\"test\",\n",
        "        leave=True,\n",
        "        dynamic_ncols=True,\n",
        "        mininterval=0.05,  # More frequent updates\n",
        "    )\n",
        "    pbar.refresh()  # Force initial display\n",
        "    \n",
        "    async def update_progress():\n",
        "        \"\"\"Update progress bar with current stats per model.\"\"\"\n",
        "        async with results_lock:\n",
        "            n = len(completed_results)\n",
        "            if n > 0:\n",
        "                # Build per-model stats\n",
        "                model_stats = {}\n",
        "                for r in completed_results:\n",
        "                    m = r.get(\"model\", \"unknown\").split(\"/\")[-1][:12]  # Short model name\n",
        "                    if m not in model_stats:\n",
        "                        model_stats[m] = {\"passed\": 0, \"total\": 0}\n",
        "                    model_stats[m][\"total\"] += 1\n",
        "                    if r.get(\"passed\"):\n",
        "                        model_stats[m][\"passed\"] += 1\n",
        "                \n",
        "                # Format: \"model1: 5/10 | model2: 3/8\"\n",
        "                model_parts = [f\"{m}: {s['passed']}/{s['total']}\" for m, s in model_stats.items()]\n",
        "                model_str = \" | \".join(model_parts)\n",
        "                \n",
        "                pbar.set_description(f\"{config['service'].upper()} | {model_str}\")\n",
        "                pbar.refresh()\n",
        "\n",
        "    async def worker(model_name, test, run_idx):\n",
        "        await acquire_rate_slot()\n",
        "        async with semaphore:\n",
        "            tid, res = await run_single_test(\n",
        "                client, model_name, test, system_prompt,\n",
        "                test_timeout_seconds=test_timeout_seconds,\n",
        "                max_iterations=max_iterations,\n",
        "            )\n",
        "            res[\"model\"] = model_name\n",
        "            res[\"test_id\"] = str(tid)\n",
        "            res[\"test_name\"] = test.name\n",
        "            res[\"run_index\"] = run_idx  # Track which run this is\n",
        "            \n",
        "            # Add metadata immediately (needed for checkpoint)\n",
        "            res[\"service\"] = config[\"service\"]\n",
        "            res[\"test_suite_name\"] = test_suite_name\n",
        "            res[\"include_api_docs\"] = include_api_docs\n",
        "            res[\"timestamp\"] = run_timestamp\n",
        "            \n",
        "            # Track result and update progress\n",
        "            async with results_lock:\n",
        "                completed_results.append(res)\n",
        "            \n",
        "            # Save to checkpoint if enabled\n",
        "            if checkpoint and checkpoint_lock:\n",
        "                async with checkpoint_lock:\n",
        "                    checkpoint.mark_completed(model_name, str(tid), run_idx, res.copy())\n",
        "                    checkpoint.save()  # Incremental save after each test\n",
        "            \n",
        "            pbar.update(1)\n",
        "            await update_progress()\n",
        "            pbar.refresh()  # Force display refresh in Jupyter\n",
        "            \n",
        "            # Log failures to tqdm (won't mess up progress bar)\n",
        "            if not res.get(\"passed\"):\n",
        "                name_short = test.name[:35] + \"...\" if len(test.name) > 35 else test.name\n",
        "                model_short = model_name.split(\"/\")[-1][:15]  # e.g., \"anthropic/claude-3\" -> \"claude-3\"\n",
        "                if res.get(\"status\") == \"timeout\":\n",
        "                    tqdm.write(f\"[TIMEOUT] {model_short} | {name_short} | {res.get('time', 0):.1f}s\")\n",
        "                elif res.get(\"status\") == \"error\":\n",
        "                    tqdm.write(f\"[ERROR] {model_short} | {name_short} | {res.get('error', 'unknown')[:50]}\")\n",
        "                else:\n",
        "                    tqdm.write(f\"[FAIL] {model_short} | {name_short} | {res.get('score')}%\")\n",
        "            \n",
        "            return res\n",
        "\n",
        "    # Create tasks from the (possibly filtered) task spec\n",
        "    tasks = [worker(model, test, run_idx) for model, test, run_idx in all_tasks_spec]\n",
        "\n",
        "    results = await asyncio.gather(*tasks)\n",
        "    pbar.close()\n",
        "    \n",
        "    # Note: Metadata is already added in the worker function for checkpoint support\n",
        "    \n",
        "    # Combine with checkpoint results if resuming\n",
        "    if checkpoint:\n",
        "        # Get all results from checkpoint (includes both old and newly added)\n",
        "        all_results = checkpoint.get_results()\n",
        "        # Filter to only this service's results\n",
        "        service_results = [r for r in all_results if r.get(\"service\") == config[\"service\"]]\n",
        "        \n",
        "        # Final summary (includes resumed results)\n",
        "        passed = sum(1 for r in service_results if r.get(\"passed\"))\n",
        "        avg_score = sum(r.get(\"score\", 0) for r in service_results) / len(service_results) if service_results else 0\n",
        "        print(f\"{config['service'].upper()} Complete: {passed}/{len(service_results)} passed ({avg_score:.1f}% avg)\")\n",
        "        if len(results) < len(service_results):\n",
        "            print(f\"  (includes {len(service_results) - len(results)} resumed from checkpoint)\")\n",
        "        \n",
        "        return service_results\n",
        "    else:\n",
        "        # Final summary\n",
        "        passed = sum(1 for r in results if r.get(\"passed\"))\n",
        "        avg_score = sum(r.get(\"score\", 0) for r in results) / len(results) if results else 0\n",
        "        print(f\"{config['service'].upper()} Complete: {passed}/{len(results)} passed ({avg_score:.1f}% avg)\")\n",
        "        \n",
        "        return results\n",
        "\n",
        "\n",
        "async def run_all_benchmarks(\n",
        "    models: list,\n",
        "    services: list = None,\n",
        "    runs_per_test: int = 1,\n",
        "    max_tests: int = None,\n",
        "    max_concurrent_models: int = 1,\n",
        "    max_concurrent_tests: int = 10,\n",
        "    max_calls_per_minute: int = 90,\n",
        "    test_timeout_seconds: int = 300,\n",
        "    max_iterations: int = 25,\n",
        "    include_api_docs: bool = True,\n",
        "    checkpoint: \"BenchmarkCheckpoint\" = None,\n",
        "):\n",
        "    \"\"\"Run benchmarks for multiple services.\n",
        "    \n",
        "    Args:\n",
        "        models: List of model identifiers to evaluate\n",
        "        services: List of services to benchmark. If None, runs all available services.\n",
        "                  Options: ['slack', 'box', 'calendar', 'linear']\n",
        "        runs_per_test: Number of times to run each test\n",
        "        max_tests: Maximum number of tests to run per service (None = all)\n",
        "        max_concurrent_models: Max parallel model evaluations\n",
        "        max_concurrent_tests: Max parallel test executions\n",
        "        max_calls_per_minute: Rate limit for API calls\n",
        "        test_timeout_seconds: Timeout per test in seconds\n",
        "        max_iterations: Max ReAct iterations per test\n",
        "        include_api_docs: Whether to include API documentation in system prompt\n",
        "        checkpoint: Optional BenchmarkCheckpoint for resuming interrupted runs\n",
        "    \n",
        "    Returns:\n",
        "        Dict[str, List[dict]]: Mapping of service name to list of results.\n",
        "            Each result dict contains (see run_benchmark_suite for full schema):\n",
        "            - prompt, status, passed, score, time, failures, error\n",
        "            - runId, model, test_id, test_name, service, test_suite_name\n",
        "            - include_api_docs (bool), timestamp (ISO format)\n",
        "            - trace: {steps, final, iterations, completed, usage}\n",
        "              - Each step includes: finish_reason, usage (per-iteration tokens/cost)\n",
        "              - usage: Total {prompt_tokens, completion_tokens, total_tokens, cost}\n",
        "            - diff: {inserts, updates, deletes}\n",
        "    \"\"\"\n",
        "    if services is None:\n",
        "        services = list(BENCHMARK_CONFIGS.keys())\n",
        "    \n",
        "    docs_status = \"with API docs\" if include_api_docs else \"NO API docs\"\n",
        "    print(f\"Benchmarks: {', '.join(s.upper() for s in services)} | {len(models)} models | {docs_status} | {test_timeout_seconds}s timeout\")\n",
        "    \n",
        "    all_results = {}\n",
        "    for service in services:\n",
        "        try:\n",
        "            results = await run_benchmark_suite(\n",
        "                service=service,\n",
        "                models=models,\n",
        "                runs_per_test=runs_per_test,\n",
        "                max_tests=max_tests,\n",
        "                max_concurrent_models=max_concurrent_models,\n",
        "                max_concurrent_tests=max_concurrent_tests,\n",
        "                max_calls_per_minute=max_calls_per_minute,\n",
        "                test_timeout_seconds=test_timeout_seconds,\n",
        "                max_iterations=max_iterations,\n",
        "                include_api_docs=include_api_docs,\n",
        "                checkpoint=checkpoint,\n",
        "            )\n",
        "            all_results[service] = results\n",
        "        except Exception as e:\n",
        "            print(f\"[ERROR] Error running {service} benchmark: {e}\")\n",
        "            all_results[service] = []\n",
        "    \n",
        "    # Overall summary\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"OVERALL SUMMARY\")\n",
        "    print(f\"{'='*60}\")\n",
        "    total_passed = 0\n",
        "    total_tests = 0\n",
        "    for service, results in all_results.items():\n",
        "        if results:\n",
        "            passed = sum(1 for r in results if r.get(\"passed\"))\n",
        "            total = len(results)\n",
        "            total_passed += passed\n",
        "            total_tests += total\n",
        "            print(f\"  {service.upper()}: {passed}/{total} passed\")\n",
        "    \n",
        "    if total_tests > 0:\n",
        "        print(f\"\\n  TOTAL: {total_passed}/{total_tests} passed ({100*total_passed/total_tests:.1f}%)\")\n",
        "    \n",
        "    return all_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============ Checkpointing System ============\n",
        "# Tracks progress and allows resuming interrupted benchmark runs\n",
        "\n",
        "import json\n",
        "import hashlib\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "from typing import Optional, Set, Tuple\n",
        "\n",
        "CHECKPOINT_DIR = Path(\"evaluation_outputs/checkpoints\")\n",
        "CHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "class BenchmarkCheckpoint:\n",
        "    \"\"\"Manages checkpoint state for benchmark runs.\n",
        "    \n",
        "    Tracks which (model, test_id, run_index) combinations have been completed,\n",
        "    allowing runs to be resumed after interruption.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, checkpoint_path: Optional[Path] = None, run_name: str = None):\n",
        "        \"\"\"Initialize checkpoint manager.\n",
        "        \n",
        "        Args:\n",
        "            checkpoint_path: Path to checkpoint file. If None, generates based on run_name.\n",
        "            run_name: Name for this run (used to generate checkpoint filename if path not given).\n",
        "        \"\"\"\n",
        "        if checkpoint_path:\n",
        "            self.checkpoint_path = Path(checkpoint_path)\n",
        "        else:\n",
        "            name = run_name or datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "            self.checkpoint_path = CHECKPOINT_DIR / f\"checkpoint_{name}.json\"\n",
        "        \n",
        "        self.completed: Set[str] = set()  # Set of \"model|test_id|run_idx\" keys\n",
        "        self.results: list = []  # Accumulated results\n",
        "        self.metadata: dict = {}  # Run metadata\n",
        "        self._lock = None  # Will be set to asyncio.Lock() when running async\n",
        "        \n",
        "    def _make_key(self, model: str, test_id: str, run_idx: int) -> str:\n",
        "        \"\"\"Create unique key for a (model, test, run) combination.\"\"\"\n",
        "        return f\"{model}|{test_id}|{run_idx}\"\n",
        "    \n",
        "    def is_completed(self, model: str, test_id: str, run_idx: int) -> bool:\n",
        "        \"\"\"Check if a specific (model, test, run) has been completed.\"\"\"\n",
        "        return self._make_key(model, test_id, run_idx) in self.completed\n",
        "    \n",
        "    def mark_completed(self, model: str, test_id: str, run_idx: int, result: dict):\n",
        "        \"\"\"Mark a (model, test, run) as completed and store result.\"\"\"\n",
        "        key = self._make_key(model, test_id, run_idx)\n",
        "        self.completed.add(key)\n",
        "        result[\"_checkpoint_key\"] = key  # Store key in result for deduplication\n",
        "        self.results.append(result)\n",
        "    \n",
        "    def save(self):\n",
        "        \"\"\"Save checkpoint to disk.\"\"\"\n",
        "        data = {\n",
        "            \"completed\": list(self.completed),\n",
        "            \"results\": self.results,\n",
        "            \"metadata\": self.metadata,\n",
        "            \"saved_at\": datetime.now().isoformat(),\n",
        "        }\n",
        "        \n",
        "        def safe_serialize(obj):\n",
        "            if isinstance(obj, bytes):\n",
        "                return obj.decode('utf-8', errors='replace')\n",
        "            return str(obj)\n",
        "        \n",
        "        with open(self.checkpoint_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(data, f, indent=2, default=safe_serialize, ensure_ascii=False)\n",
        "    \n",
        "    def load(self) -> bool:\n",
        "        \"\"\"Load checkpoint from disk. Returns True if loaded successfully.\"\"\"\n",
        "        if not self.checkpoint_path.exists():\n",
        "            return False\n",
        "        \n",
        "        try:\n",
        "            with open(self.checkpoint_path, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "            \n",
        "            self.completed = set(data.get(\"completed\", []))\n",
        "            self.results = data.get(\"results\", [])\n",
        "            self.metadata = data.get(\"metadata\", {})\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(f\"[CHECKPOINT] Warning: Failed to load checkpoint: {e}\")\n",
        "            return False\n",
        "    \n",
        "    def get_remaining_tasks(\n",
        "        self, \n",
        "        models: list, \n",
        "        tests: list, \n",
        "        runs_per_test: int\n",
        "    ) -> list:\n",
        "        \"\"\"Get list of (model, test, run_idx) tuples that haven't been completed.\"\"\"\n",
        "        remaining = []\n",
        "        for model in models:\n",
        "            for test in tests:\n",
        "                test_id = str(test.id)\n",
        "                for run_idx in range(runs_per_test):\n",
        "                    if not self.is_completed(model, test_id, run_idx):\n",
        "                        remaining.append((model, test, run_idx))\n",
        "        return remaining\n",
        "    \n",
        "    def get_completed_count(self) -> int:\n",
        "        \"\"\"Get number of completed tasks.\"\"\"\n",
        "        return len(self.completed)\n",
        "    \n",
        "    def get_results(self) -> list:\n",
        "        \"\"\"Get all accumulated results (removing internal checkpoint keys).\"\"\"\n",
        "        results = []\n",
        "        for r in self.results:\n",
        "            r_clean = {k: v for k, v in r.items() if not k.startswith(\"_checkpoint\")}\n",
        "            results.append(r_clean)\n",
        "        return results\n",
        "    \n",
        "    def summary(self) -> str:\n",
        "        \"\"\"Get summary string of checkpoint state.\"\"\"\n",
        "        return f\"Checkpoint: {self.get_completed_count()} completed, {len(self.results)} results\"\n",
        "\n",
        "\n",
        "def get_or_create_checkpoint(\n",
        "    checkpoint_path: Optional[str] = None,\n",
        "    resume: bool = True\n",
        ") -> BenchmarkCheckpoint:\n",
        "    \"\"\"Get or create a checkpoint for the current run.\n",
        "    \n",
        "    Args:\n",
        "        checkpoint_path: Path to checkpoint file. If None, creates new timestamped checkpoint.\n",
        "        resume: If True and checkpoint exists, load it. If False, start fresh.\n",
        "    \n",
        "    Returns:\n",
        "        BenchmarkCheckpoint instance\n",
        "    \"\"\"\n",
        "    checkpoint = BenchmarkCheckpoint(\n",
        "        checkpoint_path=Path(checkpoint_path) if checkpoint_path else None\n",
        "    )\n",
        "    \n",
        "    if resume and checkpoint.load():\n",
        "        print(f\"[CHECKPOINT] Resumed from {checkpoint.checkpoint_path}\")\n",
        "        print(f\"[CHECKPOINT] {checkpoint.summary()}\")\n",
        "    else:\n",
        "        print(f\"[CHECKPOINT] Starting fresh run, saving to {checkpoint.checkpoint_path}\")\n",
        "    \n",
        "    return checkpoint\n",
        "\n",
        "\n",
        "def list_checkpoints(checkpoint_dir: Path = CHECKPOINT_DIR) -> list:\n",
        "    \"\"\"List all available checkpoints.\"\"\"\n",
        "    checkpoints = sorted(checkpoint_dir.glob(\"checkpoint_*.json\"), reverse=True)\n",
        "    print(f\"Found {len(checkpoints)} checkpoints in {checkpoint_dir}:\")\n",
        "    for i, cp in enumerate(checkpoints[:10]):  # Show last 10\n",
        "        size_kb = cp.stat().st_size / 1024\n",
        "        # Load to get summary\n",
        "        try:\n",
        "            with open(cp) as f:\n",
        "                data = json.load(f)\n",
        "            n_completed = len(data.get(\"completed\", []))\n",
        "            saved_at = data.get(\"saved_at\", \"unknown\")\n",
        "            print(f\"  [{i}] {cp.name} | {n_completed} completed | {saved_at} | {size_kb:.1f}KB\")\n",
        "        except:\n",
        "            print(f\"  [{i}] {cp.name} | {size_kb:.1f}KB (error reading)\")\n",
        "    return checkpoints\n",
        "\n",
        "print(\"[OK] Checkpoint system loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Models to evaluate (uncomment to include)\n",
        "\n",
        "MODELS = [\n",
        "    \"openai/gpt-5-mini\",\n",
        "    # \"anthropic/claude-haiku-4.5\",\n",
        "    # \"anthropic/claude-sonnet-4.5\",\n",
        "    # \"anthropic/claude-opus-4.5\",\n",
        "    # \"x-ai/grok-4.1-fast\",\n",
        "    \"deepseek/deepseek-v3.2\",\n",
        "    # \"moonshotai/kimi-k2-0905\",\n",
        "    # \"qwen/qwen3-vl-235b-a22b-instruct\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "812e87c0",
        "outputId": "914dd2f4-aabf-4478-8fa5-8a1b9728ab58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Benchmarks: SLACK, BOX | 2 models | NO API docs | 300s timeout\n",
            "\n",
            "[SLACK] Slack Bench v2 | 50 tests x 2 models x 2 runs = 200 total\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:49:41<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Add emoji reactions | 66.66666666666666% | ['assertion#3 message_reactions expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:49:42<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Add emoji reactions | 66.66666666666666% | ['assertion#3 message_reactions expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:49:45<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Table Block Generation | 50.0% | ['assertion#1 messages expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:49:59<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Table Block Generation | 50.0% | ['assertion#1 messages expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:50:56<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Rich Text: Code Block and Numbered List | 50.0% | ['assertion#2 messages expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:52:22<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Lunar New Year Product Launch | 0.0% | [\"assertion#1 channels expected count {'min': 1} but got 0\"]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:53:29<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Rich Text: Bulleted List | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:55:52<?, ?test/s]           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Diwali x Thanksgiving Potluck | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:55:53<?, ?test/s]           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Diwali x Thanksgiving Potluck | 301.2s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:55:57<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Music Festival Tech Stack | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:56:10<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Music Festival Tech Stack | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:56:10<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Pierogi vs Varenyky Debug Session | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:56:11<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Pierogi vs Varenyky Debug Session | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:56:19<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Traditional Tea Ceremony Planning | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:56:21<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Traditional Tea Ceremony Planning | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:56:27<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Lunar New Year Product Launch | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:57:23<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Lunar New Year Product Launch | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:57:27<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Music Festival Tech Stack | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:58:24<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Anime Convention Booth Setup | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:58:29<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Anime Convention Booth Setup | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [1:59:33<?, ?test/s]           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Thread Q&A from DM - Circuit Tracer Rewr... | 50.0% | [\"assertion#2 message_reactions expected count {'min': 1} but got 0\"]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:00:36<?, ?test/s]           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Thread Q&A from DM - Circuit Tracer Rewr... | 50.0% | [\"assertion#2 message_reactions expected count {'min': 1} but got 0\"]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:01:11<?, ?test/s]           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Quarterly Workspace Reorganization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:01:20<?, ?test/s]           "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Quarterly Workspace Reorganization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:04:45<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Add emoji reactions | 66.66666666666666% | ['assertion#3 message_reactions expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:05:16<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Search messages in multiple channels and... | 0.0% | ['assertion#1 messages expected at least 1 match but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:05:25<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Search messages in multiple channels and... | 87.5% | ['assertion#3 messages expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:05:45<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Add emoji reactions | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:06:12<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Add emoji reaction | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:07:04<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Forward questions to another channel | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:07:07<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Search messages in multiple channels and... | 87.5% | ['assertion#3 messages expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:08:11<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Table Block Generation | 50.0% | ['assertion#1 messages expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:08:12<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Edit a thread message | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:08:32<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Table Block Generation | 50.0% | ['assertion#1 messages expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:11:32<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Rich Text: User Mention | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:12:49<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Lunar New Year Product Launch | 0.0% | [\"assertion#1 channels expected count {'min': 1} but got 0\"]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:13:12<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Cross-channel Summarization | 300.4s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:13:46<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Lunar New Year Product Launch | 0.0% | [\"assertion#1 channels expected count {'min': 1} but got 0\"]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:14:00<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Open Source Hackathon Coordination | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:14:14<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Diwali x Thanksgiving Potluck | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:14:31<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Music Festival Tech Stack | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:14:40<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Lunar New Year Product Launch | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:15:02<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Anime Convention Booth Setup | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:16:01<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Traditional Tea Ceremony Planning | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:16:01<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Lunar New Year Product Launch | 300.1s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:16:33<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Quarterly Workspace Reorganization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:18:09<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Pierogi vs Varenyky Debug Session | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:18:13<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Traditional Tea Ceremony Planning | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:18:13<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Cricket World Cup Watch Party | 300.2s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:18:47<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Quarterly Workspace Reorganization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:19:01<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Music Festival Tech Stack | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:19:02<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Thread Q&A from DM - Circuit Tracer Rewr... | 50.0% | [\"assertion#2 message_reactions expected count {'min': 1} but got 0\"]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:19:14<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Thread Q&A from DM - Circuit Tracer Rewr... | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:19:41<?, ?test/s]            "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Music Festival Tech Stack | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 145/200 | 72.5% pass | 76.4% avg: 100%|| 200/200 [33:58<00:00, 10.19s/test]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Channel Audit and Rename | 300.0s\n",
            "SLACK Complete: 145/200 passed (76.4% avg)\n",
            "\n",
            "[BOX] Box Bench v2 | 48 tests x 2 models x 2 runs = 192 total\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:21:50<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 1: Create Hub | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:22:15<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 1: Create Hub | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:23:31<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 4: Rename Folder from CSV (CPI) | 0.0% | ['assertion#1 box_folders expected at least 1 match but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:24:14<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 2: Hub Setup | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:24:20<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 2: Hub Setup | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:24:23<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 4: Upload TXT named from CSV (Tran... | 0.0% | ['assertion#1 box_files expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:24:51<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 4: Upload TXT named from CSV (Tran... | 0.0% | ['assertion#1 box_files expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:26:06<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Ambiguous Sorting | 50.0% | ['assertion#1 box_files expected at least 1 match but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:26:19<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Cross-Folder Dedup | 0.0% | ['assertion#1 box_files expected at least 1 match but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:26:23<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Ambiguous Sorting | 50.0% | ['assertion#1 box_files expected at least 1 match but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:26:24<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Organize Research Hub | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:26:27<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Cross-Folder Dedup | 0.0% | ['assertion#1 box_files expected at least 1 match but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:27:58<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Organize Research Hub | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:29:15<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Curate FOMC Hub | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:29:31<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Curate FOMC Hub | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:29:51<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Organize By Extension (Flatten) | 75.0% | ['assertion#4 box_folders expected count 6 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:30:00<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Organize By Extension (Flatten) | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:31:49<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Tag All PDFs | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:32:21<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 4: Cryptozoology Expedition Organi... | 85.71428571428571% | ['assertion#7 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:32:27<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 5: Economic Domain Organization | 303.3s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:32:30<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 5: Economic Domain Organization | 306.1s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:33:05<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Cryptozoology Expedition Organi... | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:33:14<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Tea Ceremony Ro Season | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:33:20<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Tea Ceremony Ro Season | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:33:26<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Moog Minimoog Restoration | 300.6s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:33:32<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Moog Minimoog Restoration | 302.7s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:34:02<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 5: Rare Books Conservation Audit | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:34:30<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 5: Rare Books Conservation Audit | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:34:38<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: History Archive Reorganization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:34:54<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: History Archive Reorganization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:35:03<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Conservation Audit Shared Link | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:35:12<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Conservation Audit Shared Link | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:36:52<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Demographics 2025 Reorganizatio... | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:37:26<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Demographics 2025 Reorganizatio... | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:37:31<?, ?test/s]       "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Google Earnings Size Audit | 301.4s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:37:34<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Google Earnings Size Audit | 300.9s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:38:24<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 1: Create Folder | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:39:47<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 1: Create Hub | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:41:08<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 1: Create Hub | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:42:40<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Comment and Task | 300.7s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:43:13<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Count Files and Set Description | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:43:58<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 4: Rename Folder from CSV (CPI) | 0.0% | ['assertion#1 box_folders expected at least 1 match but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:44:41<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 4: Upload TXT named from CSV (Tran... | 0.0% | ['assertion#1 box_files expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:44:43<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Search Read Move | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:44:50<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Hub Setup | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:44:56<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Hub Setup | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:45:28<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Find Duplicates, Delete Misfile... | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:45:55<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 4: Find Duplicates, Delete Misfile... | 50.0% | ['assertion#2 box_files expected at least 1 match but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:46:26<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 4: Upload TXT named from CSV (Tran... | 0.0% | ['assertion#1 box_files expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:48:17<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Ambiguous Sorting | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:48:38<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Ambiguous Sorting | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:49:20<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Dyslexic User Typo Fix | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:49:56<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Organize Research Hub | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:50:06<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Organize Research Hub | 303.8s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:50:31<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Cross-Folder Dedup | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:50:58<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Cross-Folder Dedup | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:51:07<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Description From Name | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:51:28<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Description From Name | 303.7s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:51:34<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Organize By Extension (Flatten) | 302.9s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:51:38<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Organize By Extension (Flatten) | 300.1s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:53:05<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Typo Fix (Computational) | 306.2s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:54:24<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 1: Upload and Delete File (Trash) | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:55:03<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 1: Upload and Delete File (Trash) | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:55:09<?, ?test/s]         "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Upload New Version | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:55:36<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Upload New Version | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:56:03<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Remove Duplicate (Buenos Aires) | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:56:11<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 3: Curate FOMC Hub | 0.0% | ['assertion#1 box_hubs expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:56:17<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[FAIL] Level 4: Read and Extract Slogan | 0.0% | ['assertion#1 box_comments expected count 1 but got 0']\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:56:22<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Remove Duplicate (Buenos Aires) | 310.4s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:56:28<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Curate FOMC Hub | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:56:38<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Tag All PDFs | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:56:45<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Tag All PDFs | 302.9s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:56:53<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 1: List File Comments | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:58:14<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 5: Economic Domain Organization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [2:59:28<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 5: Economic Domain Organization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:00:07<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Cryptozoology Expedition Organi... | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:00:13<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Cryptozoology Expedition Organi... | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:00:18<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Tea Ceremony Ro Season | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:00:39<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Tea Ceremony Ro Season | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:01:09<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Conservation Audit Shared Link | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7415) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7418) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7420) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7426) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7428) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:01:17<?, ?test/s]          python(7432) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Demographics 2025 Reorganizatio... | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7435) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7437) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7439) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7441) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:01:22<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: History Archive Reorganization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7444) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7446) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7448) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:01:27<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 2: Conservation Audit Shared Link | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7450) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7452) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7455) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:01:31<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: History Archive Reorganization | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7457) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7459) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7485) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7488) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7653) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:01:45<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Google Earnings Size Audit | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7657) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7659) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7667) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7669) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:01:49<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 3: Google Earnings Size Audit | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7678) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7682) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7686) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7688) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:01:59<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Demographics 2025 Reorganizatio... | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7695) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7697) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7699) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7712) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7714) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7716) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7718) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7720) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7722) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7727) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7729) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7736) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7738) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7742) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7746) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7753) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7755) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7757) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7762) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:02:41<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 5: Rare Books Conservation Audit | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7781) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7787) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7792) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7794) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7797) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7801) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7808) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:03:19<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 5: Rare Books Conservation Audit | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7814) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7826) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7842) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7844) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7849) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7853) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7858) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7863) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7867) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7869) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7874) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7877) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7879) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7882) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7887) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7889) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7903) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7939) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7947) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7956) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "SLACK | 0/100 | 0.0% pass | 0.0% avg:   0%|          | 0/100 [3:04:35<?, ?test/s]          "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Moog Minimoog Restoration | 300.0s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(7971) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7974) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(7984) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8017) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8061) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "                                                                                 \n",
            "BOX | 101/192 | 52.6% pass | 54.2% avg: 100%|| 192/192 [44:51<00:00, 14.02s/test]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TIMEOUT] Level 4: Moog Minimoog Restoration | 300.0s\n",
            "BOX Complete: 101/192 passed (54.2% avg)\n",
            "\n",
            "============================================================\n",
            "OVERALL SUMMARY\n",
            "============================================================\n",
            "  SLACK: 145/200 passed\n",
            "  BOX: 101/192 passed\n",
            "\n",
            "  TOTAL: 246/392 passed (62.8%)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "python(8553) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8563) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8653) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8670) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8704) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8705) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8708) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8715) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8719) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8743) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8747) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8799) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
            "python(8821) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        }
      ],
      "source": [
        "# Runtime Settings (all passed to benchmark functions)\n",
        "\n",
        "BENCHMARK_SETTINGS = {\n",
        "    \"models\": MODELS,                    # Models to evaluate (from cell above)\n",
        "    \"runs_per_test\": 2,                  # Number of runs per test\n",
        "    \"max_tests\": None,                   # None = all tests, or set a limit\n",
        "    \"max_concurrent_models\": 1,          # Parallel model evaluations\n",
        "    \"max_concurrent_tests\": 15,          # Parallel test executions\n",
        "    \"max_calls_per_minute\": 180,         # API rate limit\n",
        "    \"test_timeout_seconds\": 300,         # 5 minutes per test\n",
        "    \"max_iterations\": 25,                # Max ReAct iterations\n",
        "    \"include_api_docs\": False,           # Include API docs in prompt (False = agent explores)\n",
        "}\n",
        "\n",
        "# ============ Checkpointing (optional) ============\n",
        "# Enable to resume interrupted runs. Checkpoint saves after each test.\n",
        "\n",
        "# Option 1: Fresh run with new checkpoint\n",
        "checkpoint = get_or_create_checkpoint(resume=False)\n",
        "\n",
        "# Option 2: Resume from latest checkpoint (comment out Option 1)\n",
        "# checkpoints = list_checkpoints()  # List available checkpoints\n",
        "# checkpoint = get_or_create_checkpoint(checkpoint_path=str(checkpoints[0]), resume=True)\n",
        "\n",
        "# Option 3: No checkpointing (comment out both options above)\n",
        "# checkpoint = None\n",
        "\n",
        "# Add checkpoint to settings\n",
        "BENCHMARK_SETTINGS[\"checkpoint\"] = checkpoint\n",
        "\n",
        "# ============ Run Benchmark ============\n",
        "\n",
        "# Single service:\n",
        "#results = await run_benchmark_suite(service=\"slack\", **BENCHMARK_SETTINGS)\n",
        "\n",
        "# Multiple services:\n",
        "all_results = await run_all_benchmarks(services=[\"slack\", \"box\"], **BENCHMARK_SETTINGS)\n",
        "\n",
        "# All services:\n",
        "# all_results = await run_all_benchmarks(**BENCHMARK_SETTINGS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[OK] Analysis functions loaded\n"
          ]
        }
      ],
      "source": [
        "# ============ Analysis Functions ============\n",
        "# Reusable functions for analyzing benchmark results\n",
        "\n",
        "def styled_display(df, format_str=\"{:.1f}%\", gradient_cols=None):\n",
        "    \"\"\"Display dataframe with styling if jinja2 is available, otherwise plain.\"\"\"\n",
        "    try:\n",
        "        styled = df.style.format(format_str)\n",
        "        if gradient_cols:\n",
        "            cols = [c for c in gradient_cols if c in df.columns]\n",
        "            if cols:\n",
        "                styled = styled.background_gradient(cmap=\"RdYlGn\", vmin=0, vmax=100, subset=cols)\n",
        "        display(styled)\n",
        "    except (ImportError, AttributeError):\n",
        "        display(df)\n",
        "\n",
        "\n",
        "def analyze_results(results: list):\n",
        "    \"\"\"Display comprehensive analysis tables for benchmark results.\n",
        "    \n",
        "    Args:\n",
        "        results: List of result dicts from benchmark runs\n",
        "    \"\"\"\n",
        "    if not results:\n",
        "        print(\"No results to analyze.\")\n",
        "        return\n",
        "    \n",
        "    df = pd.DataFrame(results)\n",
        "    \n",
        "    # Helper to format model names (shorter)\n",
        "    df[\"model_short\"] = df[\"model\"].apply(lambda x: x.split(\"/\")[-1] if \"/\" in str(x) else x)\n",
        "\n",
        "    # ============ 1. Overall Leaderboard by Model ============\n",
        "    display(HTML(\"<h3>1. Overall Results by Model</h3>\"))\n",
        "    leaderboard = df.groupby(\"model_short\").agg(\n",
        "        passed=(\"passed\", \"sum\"),\n",
        "        total=(\"passed\", \"count\"),\n",
        "        avg_score=(\"score\", \"mean\"),\n",
        "        avg_time=(\"time\", \"mean\")\n",
        "    ).reset_index()\n",
        "    leaderboard[\"pass_rate\"] = (leaderboard[\"passed\"] / leaderboard[\"total\"] * 100).round(1)\n",
        "    leaderboard = leaderboard.sort_values(\"pass_rate\", ascending=False)\n",
        "    display(leaderboard)\n",
        "\n",
        "    # ============ 2. Results by Model and Service ============\n",
        "    display(HTML(\"<h3>2. Results by Model and Service</h3>\"))\n",
        "    by_model_service = df.groupby([\"model_short\", \"service\"]).agg(\n",
        "        passed=(\"passed\", \"sum\"),\n",
        "        total=(\"passed\", \"count\"),\n",
        "        avg_score=(\"score\", \"mean\"),\n",
        "    ).reset_index()\n",
        "    by_model_service[\"pass_rate\"] = (by_model_service[\"passed\"] / by_model_service[\"total\"] * 100).round(1)\n",
        "    \n",
        "    # Pivot for better readability\n",
        "    pivot_pass_rate = by_model_service.pivot(index=\"model_short\", columns=\"service\", values=\"pass_rate\")\n",
        "    pivot_pass_rate[\"OVERALL\"] = leaderboard.set_index(\"model_short\")[\"pass_rate\"]\n",
        "    pivot_pass_rate = pivot_pass_rate.sort_values(\"OVERALL\", ascending=False)\n",
        "    styled_display(pivot_pass_rate, gradient_cols=list(pivot_pass_rate.columns))\n",
        "\n",
        "    # ============ 3. Results by Service (all models) ============\n",
        "    display(HTML(\"<h3>3. Results by Service (All Models)</h3>\"))\n",
        "    by_service = df.groupby(\"service\").agg(\n",
        "        passed=(\"passed\", \"sum\"),\n",
        "        total=(\"passed\", \"count\"),\n",
        "        avg_score=(\"score\", \"mean\"),\n",
        "        avg_time=(\"time\", \"mean\")\n",
        "    ).reset_index()\n",
        "    by_service[\"pass_rate\"] = (by_service[\"passed\"] / by_service[\"total\"] * 100).round(1)\n",
        "    by_service = by_service.sort_values(\"pass_rate\", ascending=False)\n",
        "    display(by_service)\n",
        "\n",
        "    # ============ 4. With Docs vs Without Docs ============\n",
        "    if \"include_api_docs\" in df.columns and df[\"include_api_docs\"].nunique() > 1:\n",
        "        display(HTML(\"<h3>4. With API Docs vs Without API Docs</h3>\"))\n",
        "        \n",
        "        # Overall by docs\n",
        "        by_docs = df.groupby(\"include_api_docs\").agg(\n",
        "            passed=(\"passed\", \"sum\"),\n",
        "            total=(\"passed\", \"count\"),\n",
        "            avg_score=(\"score\", \"mean\"),\n",
        "            avg_time=(\"time\", \"mean\")\n",
        "        ).reset_index()\n",
        "        by_docs[\"pass_rate\"] = (by_docs[\"passed\"] / by_docs[\"total\"] * 100).round(1)\n",
        "        by_docs[\"include_api_docs\"] = by_docs[\"include_api_docs\"].map({True: \"With Docs\", False: \"Without Docs\"})\n",
        "        display(by_docs)\n",
        "        \n",
        "        # By model and docs\n",
        "        display(HTML(\"<h4>4a. By Model: With vs Without Docs</h4>\"))\n",
        "        by_model_docs = df.groupby([\"model_short\", \"include_api_docs\"]).agg(\n",
        "            passed=(\"passed\", \"sum\"),\n",
        "            total=(\"passed\", \"count\"),\n",
        "            avg_score=(\"score\", \"mean\"),\n",
        "        ).reset_index()\n",
        "        by_model_docs[\"pass_rate\"] = (by_model_docs[\"passed\"] / by_model_docs[\"total\"] * 100).round(1)\n",
        "        by_model_docs[\"docs\"] = by_model_docs[\"include_api_docs\"].map({True: \"With Docs\", False: \"Without Docs\"})\n",
        "        \n",
        "        pivot_docs = by_model_docs.pivot(index=\"model_short\", columns=\"docs\", values=\"pass_rate\")\n",
        "        if \"With Docs\" in pivot_docs.columns and \"Without Docs\" in pivot_docs.columns:\n",
        "            pivot_docs[\"Delta\"] = pivot_docs[\"With Docs\"] - pivot_docs[\"Without Docs\"]\n",
        "            pivot_docs = pivot_docs.sort_values(\"Delta\", ascending=False)\n",
        "        styled_display(pivot_docs, gradient_cols=[\"With Docs\", \"Without Docs\"])\n",
        "        \n",
        "        # By service and docs\n",
        "        display(HTML(\"<h4>4b. By Service: With vs Without Docs</h4>\"))\n",
        "        by_service_docs = df.groupby([\"service\", \"include_api_docs\"]).agg(\n",
        "            passed=(\"passed\", \"sum\"),\n",
        "            total=(\"passed\", \"count\"),\n",
        "            avg_score=(\"score\", \"mean\"),\n",
        "        ).reset_index()\n",
        "        by_service_docs[\"pass_rate\"] = (by_service_docs[\"passed\"] / by_service_docs[\"total\"] * 100).round(1)\n",
        "        by_service_docs[\"docs\"] = by_service_docs[\"include_api_docs\"].map({True: \"With Docs\", False: \"Without Docs\"})\n",
        "        \n",
        "        pivot_service_docs = by_service_docs.pivot(index=\"service\", columns=\"docs\", values=\"pass_rate\")\n",
        "        if \"With Docs\" in pivot_service_docs.columns and \"Without Docs\" in pivot_service_docs.columns:\n",
        "            pivot_service_docs[\"Delta\"] = pivot_service_docs[\"With Docs\"] - pivot_service_docs[\"Without Docs\"]\n",
        "        styled_display(pivot_service_docs, gradient_cols=[\"With Docs\", \"Without Docs\"])\n",
        "    else:\n",
        "        docs_status = df[\"include_api_docs\"].iloc[0] if \"include_api_docs\" in df.columns else \"unknown\"\n",
        "        print(f\"\\n[Note] All results have include_api_docs={docs_status}, no comparison available.\")\n",
        "\n",
        "    # ============ 5. Usage Summary ============\n",
        "    display(HTML(\"<h3>5. Usage Summary</h3>\"))\n",
        "    \n",
        "    # Extract usage data into dataframe columns\n",
        "    def extract_tokens(row):\n",
        "        trace = row[\"trace\"] if \"trace\" in row and isinstance(row[\"trace\"], dict) else {}\n",
        "        usage = trace.get(\"usage\", {}) if isinstance(trace, dict) else {}\n",
        "        return usage.get(\"total_tokens\", 0) if isinstance(usage, dict) else 0\n",
        "    \n",
        "    def extract_cost(row):\n",
        "        trace = row[\"trace\"] if \"trace\" in row and isinstance(row[\"trace\"], dict) else {}\n",
        "        usage = trace.get(\"usage\", {}) if isinstance(trace, dict) else {}\n",
        "        return usage.get(\"cost\", 0) if isinstance(usage, dict) else 0\n",
        "    \n",
        "    df[\"total_tokens\"] = df.apply(extract_tokens, axis=1)\n",
        "    df[\"cost\"] = df.apply(extract_cost, axis=1)\n",
        "    \n",
        "    print(f\"Total: {df['total_tokens'].sum():,.0f} tokens | ${df['cost'].sum():.4f} USD\")\n",
        "    \n",
        "    # Usage by model\n",
        "    display(HTML(\"<h4>5a. Usage by Model</h4>\"))\n",
        "    usage_by_model = df.groupby(\"model_short\").agg(\n",
        "        tests=(\"model_short\", \"count\"),\n",
        "        tokens=(\"total_tokens\", \"sum\"),\n",
        "        cost=(\"cost\", \"sum\"),\n",
        "    ).reset_index()\n",
        "    usage_by_model[\"tokens_per_test\"] = (usage_by_model[\"tokens\"] / usage_by_model[\"tests\"]).round(0).astype(int)\n",
        "    usage_by_model[\"cost_per_test\"] = (usage_by_model[\"cost\"] / usage_by_model[\"tests\"]).round(4)\n",
        "    usage_by_model = usage_by_model.sort_values(\"cost\", ascending=False)\n",
        "    display(usage_by_model)\n",
        "    \n",
        "    # Usage by model and include_api_docs\n",
        "    if \"include_api_docs\" in df.columns and df[\"include_api_docs\"].nunique() > 1:\n",
        "        display(HTML(\"<h4>5b. Usage by Model: With vs Without Docs</h4>\"))\n",
        "        usage_by_model_docs = df.groupby([\"model_short\", \"include_api_docs\"]).agg(\n",
        "            tests=(\"model_short\", \"count\"),\n",
        "            tokens=(\"total_tokens\", \"sum\"),\n",
        "            cost=(\"cost\", \"sum\"),\n",
        "        ).reset_index()\n",
        "        usage_by_model_docs[\"tokens_per_test\"] = (usage_by_model_docs[\"tokens\"] / usage_by_model_docs[\"tests\"]).round(0).astype(int)\n",
        "        usage_by_model_docs[\"cost_per_test\"] = (usage_by_model_docs[\"cost\"] / usage_by_model_docs[\"tests\"]).round(4)\n",
        "        usage_by_model_docs[\"docs\"] = usage_by_model_docs[\"include_api_docs\"].map({True: \"With Docs\", False: \"Without Docs\"})\n",
        "        \n",
        "        # Pivot for comparison\n",
        "        pivot_tokens = usage_by_model_docs.pivot(index=\"model_short\", columns=\"docs\", values=\"tokens_per_test\")\n",
        "        pivot_cost = usage_by_model_docs.pivot(index=\"model_short\", columns=\"docs\", values=\"cost_per_test\")\n",
        "        \n",
        "        print(\"Tokens per test:\")\n",
        "        display(pivot_tokens)\n",
        "        print(\"\\nCost per test:\")\n",
        "        display(pivot_cost)\n",
        "\n",
        "\n",
        "def load_and_analyze(file_path: str = None):\n",
        "    \"\"\"Load results from a JSON file and analyze them.\n",
        "    \n",
        "    Args:\n",
        "        file_path: Path to JSON file. If None, lists available files.\n",
        "    \n",
        "    Returns:\n",
        "        list: Loaded results (or None if just listing files)\n",
        "    \"\"\"\n",
        "    if file_path is None:\n",
        "        files = list_result_files()\n",
        "        print(\"\\nUsage: load_and_analyze('path/to/file.json')\")\n",
        "        print(\"   or: load_and_analyze(str(files[0]))\")\n",
        "        return None\n",
        "    \n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        results = json.load(f)\n",
        "    \n",
        "    print(f\"Loaded {len(results)} results from {file_path}\\n\")\n",
        "    analyze_results(results)\n",
        "    return results\n",
        "\n",
        "print(\"[OK] Analysis functions loaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3>1. Overall Results by Model</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_short</th>\n",
              "      <th>passed</th>\n",
              "      <th>total</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>avg_time</th>\n",
              "      <th>pass_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gpt-5-mini</td>\n",
              "      <td>136</td>\n",
              "      <td>196</td>\n",
              "      <td>72.673712</td>\n",
              "      <td>118.211122</td>\n",
              "      <td>69.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deepseek-v3.2</td>\n",
              "      <td>110</td>\n",
              "      <td>196</td>\n",
              "      <td>58.375850</td>\n",
              "      <td>211.344847</td>\n",
              "      <td>56.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model_short  passed  total  avg_score    avg_time  pass_rate\n",
              "1     gpt-5-mini     136    196  72.673712  118.211122       69.4\n",
              "0  deepseek-v3.2     110    196  58.375850  211.344847       56.1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>2. Results by Model and Service</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>service</th>\n",
              "      <th>box</th>\n",
              "      <th>slack</th>\n",
              "      <th>OVERALL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_short</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gpt-5-mini</th>\n",
              "      <td>62.5</td>\n",
              "      <td>76.0</td>\n",
              "      <td>69.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek-v3.2</th>\n",
              "      <td>42.7</td>\n",
              "      <td>69.0</td>\n",
              "      <td>56.1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "service         box  slack  OVERALL\n",
              "model_short                        \n",
              "gpt-5-mini     62.5   76.0     69.4\n",
              "deepseek-v3.2  42.7   69.0     56.1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>3. Results by Service (All Models)</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>service</th>\n",
              "      <th>passed</th>\n",
              "      <th>total</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>avg_time</th>\n",
              "      <th>pass_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>slack</td>\n",
              "      <td>145</td>\n",
              "      <td>200</td>\n",
              "      <td>76.37500</td>\n",
              "      <td>142.778750</td>\n",
              "      <td>72.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>box</td>\n",
              "      <td>101</td>\n",
              "      <td>192</td>\n",
              "      <td>54.22247</td>\n",
              "      <td>187.693854</td>\n",
              "      <td>52.6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  service  passed  total  avg_score    avg_time  pass_rate\n",
              "1   slack     145    200   76.37500  142.778750       72.5\n",
              "0     box     101    192   54.22247  187.693854       52.6"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Note] All results have include_api_docs=False, no comparison available.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<h3>5. Usage Summary</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total: 14,905,402 tokens | $4.6037 USD\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<h4>5a. Usage by Model</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_short</th>\n",
              "      <th>tests</th>\n",
              "      <th>tokens</th>\n",
              "      <th>cost</th>\n",
              "      <th>tokens_per_test</th>\n",
              "      <th>cost_per_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gpt-5-mini</td>\n",
              "      <td>196</td>\n",
              "      <td>7848985</td>\n",
              "      <td>2.582950</td>\n",
              "      <td>40046</td>\n",
              "      <td>0.0132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deepseek-v3.2</td>\n",
              "      <td>196</td>\n",
              "      <td>7056417</td>\n",
              "      <td>2.020707</td>\n",
              "      <td>36002</td>\n",
              "      <td>0.0103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model_short  tests   tokens      cost  tokens_per_test  cost_per_test\n",
              "1     gpt-5-mini    196  7848985  2.582950            40046         0.0132\n",
              "0  deepseek-v3.2    196  7056417  2.020707            36002         0.0103"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results saved to evaluation_outputs/full_results_20260130_160921.json\n"
          ]
        }
      ],
      "source": [
        "# Handle both single service (results = list) and multi-service (all_results = dict)\n",
        "if 'all_results' in dir() and all_results:\n",
        "    # Flatten all_results dict into a single list\n",
        "    results_to_save = []\n",
        "    for service, service_results in all_results.items():\n",
        "        results_to_save.extend(service_results)\n",
        "elif 'results' in dir() and results:\n",
        "    results_to_save = results\n",
        "else:\n",
        "    results_to_save = []\n",
        "\n",
        "if results_to_save:\n",
        "    # Analyze results (uses analyze_results function from cell below)\n",
        "    analyze_results(results_to_save)\n",
        "    \n",
        "    # Save results to JSON\n",
        "    ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    output_path = OUTPUT_DIR / f\"full_results_{ts}.json\"\n",
        "\n",
        "    def safe_serialize(obj):\n",
        "        if isinstance(obj, bytes):\n",
        "            return obj.decode('utf-8', errors='replace')\n",
        "        return str(obj)\n",
        "\n",
        "    try:\n",
        "        with open(output_path, 'w', encoding='utf-8') as f:\n",
        "            json.dump(results_to_save, f, indent=2, default=safe_serialize, ensure_ascii=False)\n",
        "        print(f\"\\nResults saved to {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error saving JSON: {e}\")\n",
        "else:\n",
        "    print(\"No results generated.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Utility: Merge Multiple Result Files\n",
        "\n",
        "def list_result_files(output_dir: Path = OUTPUT_DIR) -> list:\n",
        "    \"\"\"List all result JSON files in the output directory.\"\"\"\n",
        "    files = sorted(output_dir.glob(\"full_results_*.json\"))\n",
        "    print(f\"Found {len(files)} result files in {output_dir}:\")\n",
        "    for i, f in enumerate(files):\n",
        "        size_kb = f.stat().st_size / 1024\n",
        "        print(f\"  [{i}] {f.name} ({size_kb:.1f} KB)\")\n",
        "    return files\n",
        "\n",
        "\n",
        "def merge_result_files(\n",
        "    files: list = None,\n",
        "    output_dir: Path = OUTPUT_DIR,\n",
        "    output_name: str = None,\n",
        "    deduplicate: bool = False,\n",
        ") -> list:\n",
        "    \"\"\"Merge multiple result JSON files into one.\n",
        "    \n",
        "    Args:\n",
        "        files: List of file paths to merge. If None, merges all files in output_dir.\n",
        "        output_dir: Directory containing result files (used if files=None)\n",
        "        output_name: Output filename. If None, generates timestamped name.\n",
        "        deduplicate: If True, removes duplicate entries (same test_id + model + timestamp)\n",
        "    \n",
        "    Returns:\n",
        "        list: Merged results\n",
        "    \"\"\"\n",
        "    if files is None:\n",
        "        files = sorted(output_dir.glob(\"full_results_*.json\"))\n",
        "    \n",
        "    if not files:\n",
        "        print(\"No files to merge.\")\n",
        "        return []\n",
        "    \n",
        "    print(f\"Merging {len(files)} files...\")\n",
        "    \n",
        "    all_results = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            with open(f, 'r', encoding='utf-8') as fp:\n",
        "                data = json.load(fp)\n",
        "                if isinstance(data, list):\n",
        "                    all_results.extend(data)\n",
        "                    print(f\"  + {f.name}: {len(data)} results\")\n",
        "                else:\n",
        "                    print(f\"  ! {f.name}: unexpected format (not a list)\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ! {f.name}: error loading - {e}\")\n",
        "    \n",
        "    print(f\"\\nTotal: {len(all_results)} results\")\n",
        "    \n",
        "    # Deduplicate if requested\n",
        "    if deduplicate and all_results:\n",
        "        seen = set()\n",
        "        unique_results = []\n",
        "        for r in all_results:\n",
        "            # Create unique key from test_id, model, timestamp, and run_index\n",
        "            # run_index distinguishes multiple runs of the same test\n",
        "            key = (r.get(\"test_id\"), r.get(\"model\"), r.get(\"timestamp\"), r.get(\"run_index\", 0))\n",
        "            if key not in seen:\n",
        "                seen.add(key)\n",
        "                unique_results.append(r)\n",
        "        \n",
        "        removed = len(all_results) - len(unique_results)\n",
        "        if removed > 0:\n",
        "            print(f\"Deduplicated: removed {removed} duplicates, {len(unique_results)} unique results\")\n",
        "        all_results = unique_results\n",
        "    \n",
        "    # Save merged results\n",
        "    if output_name is None:\n",
        "        ts = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        output_name = f\"merged_results_{ts}.json\"\n",
        "    \n",
        "    output_path = output_dir / output_name\n",
        "    \n",
        "    def safe_serialize(obj):\n",
        "        if isinstance(obj, bytes):\n",
        "            return obj.decode('utf-8', errors='replace')\n",
        "        return str(obj)\n",
        "    \n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(all_results, f, indent=2, default=safe_serialize, ensure_ascii=False)\n",
        "    \n",
        "    print(f\"\\nSaved to: {output_path}\")\n",
        "    \n",
        "    # Summary by model and service\n",
        "    if all_results:\n",
        "        df = pd.DataFrame(all_results)\n",
        "        print(\"\\n--- Summary by Model ---\")\n",
        "        model_summary = df.groupby(\"model\").agg(\n",
        "            tests=(\"passed\", \"count\"),\n",
        "            passed=(\"passed\", \"sum\"),\n",
        "            avg_score=(\"score\", \"mean\"),\n",
        "        ).reset_index()\n",
        "        model_summary[\"pass_rate\"] = (100 * model_summary[\"passed\"] / model_summary[\"tests\"]).round(1)\n",
        "        display(model_summary)\n",
        "        \n",
        "        if \"service\" in df.columns:\n",
        "            print(\"\\n--- Summary by Service ---\")\n",
        "            service_summary = df.groupby(\"service\").agg(\n",
        "                tests=(\"passed\", \"count\"),\n",
        "                passed=(\"passed\", \"sum\"),\n",
        "                avg_score=(\"score\", \"mean\"),\n",
        "            ).reset_index()\n",
        "            service_summary[\"pass_rate\"] = (100 * service_summary[\"passed\"] / service_summary[\"tests\"]).round(1)\n",
        "            display(service_summary)\n",
        "    \n",
        "    return all_results\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "# files = list_result_files()\n",
        "# merged = merge_result_files()  # Merge all files\n",
        "# merged = merge_result_files(files=[files[0], files[2]])  # Merge specific files\n",
        "# merged = merge_result_files(deduplicate=True)  # Merge and remove duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2 result files in evaluation_outputs:\n",
            "  [0] full_results_20260130_020702.json (37349.6 KB)\n",
            "  [1] full_results_20260130_154351.json (62490.7 KB)\n",
            "Merging 2 files...\n",
            "  + full_results_20260130_020702.json: 392 results\n",
            "  + full_results_20260130_154351.json: 392 results\n",
            "\n",
            "Total: 784 results\n",
            "\n",
            "Saved to: evaluation_outputs/merged_results_20260130_155942.json\n",
            "\n",
            "--- Summary by Model ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>tests</th>\n",
              "      <th>passed</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>pass_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deepseek/deepseek-v3.2</td>\n",
              "      <td>392</td>\n",
              "      <td>246</td>\n",
              "      <td>65.593112</td>\n",
              "      <td>62.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>openai/gpt-5-mini</td>\n",
              "      <td>392</td>\n",
              "      <td>295</td>\n",
              "      <td>79.058131</td>\n",
              "      <td>75.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    model  tests  passed  avg_score  pass_rate\n",
              "0  deepseek/deepseek-v3.2    392     246  65.593112       62.8\n",
              "1       openai/gpt-5-mini    392     295  79.058131       75.3"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Summary by Service ---\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>service</th>\n",
              "      <th>tests</th>\n",
              "      <th>passed</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>pass_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>box</td>\n",
              "      <td>384</td>\n",
              "      <td>251</td>\n",
              "      <td>67.686012</td>\n",
              "      <td>65.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>slack</td>\n",
              "      <td>400</td>\n",
              "      <td>290</td>\n",
              "      <td>76.779647</td>\n",
              "      <td>72.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  service  tests  passed  avg_score  pass_rate\n",
              "0     box    384     251  67.686012       65.4\n",
              "1   slack    400     290  76.779647       72.5"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# List available result files\n",
        "files = list_result_files()\n",
        "\n",
        "#print(files)\n",
        "\n",
        "# Merge all files with deduplication\n",
        "merged = merge_result_files(deduplicate=False)\n",
        "\n",
        "# Alternative options:\n",
        "# merged = merge_result_files()  # Merge all without deduplication\n",
        "# merged = merge_result_files(files=[files[0], files[-1]])  # Merge specific files only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<h3>1. Overall Results by Model</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_short</th>\n",
              "      <th>passed</th>\n",
              "      <th>total</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>avg_time</th>\n",
              "      <th>pass_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gpt-5-mini</td>\n",
              "      <td>295</td>\n",
              "      <td>392</td>\n",
              "      <td>79.058131</td>\n",
              "      <td>102.600408</td>\n",
              "      <td>75.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deepseek-v3.2</td>\n",
              "      <td>246</td>\n",
              "      <td>392</td>\n",
              "      <td>65.593112</td>\n",
              "      <td>184.481658</td>\n",
              "      <td>62.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model_short  passed  total  avg_score    avg_time  pass_rate\n",
              "1     gpt-5-mini     295    392  79.058131  102.600408       75.3\n",
              "0  deepseek-v3.2     246    392  65.593112  184.481658       62.8"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>2. Results by Model and Service</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>service</th>\n",
              "      <th>box</th>\n",
              "      <th>slack</th>\n",
              "      <th>OVERALL</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_short</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>gpt-5-mini</th>\n",
              "      <td>73.4</td>\n",
              "      <td>77.0</td>\n",
              "      <td>75.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>deepseek-v3.2</th>\n",
              "      <td>57.3</td>\n",
              "      <td>68.0</td>\n",
              "      <td>62.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "service         box  slack  OVERALL\n",
              "model_short                        \n",
              "gpt-5-mini     73.4   77.0     75.3\n",
              "deepseek-v3.2  57.3   68.0     62.8"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>3. Results by Service (All Models)</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>service</th>\n",
              "      <th>passed</th>\n",
              "      <th>total</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>avg_time</th>\n",
              "      <th>pass_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>slack</td>\n",
              "      <td>290</td>\n",
              "      <td>400</td>\n",
              "      <td>76.779647</td>\n",
              "      <td>132.193625</td>\n",
              "      <td>72.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>box</td>\n",
              "      <td>251</td>\n",
              "      <td>384</td>\n",
              "      <td>67.686012</td>\n",
              "      <td>155.361250</td>\n",
              "      <td>65.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  service  passed  total  avg_score    avg_time  pass_rate\n",
              "1   slack     290    400  76.779647  132.193625       72.5\n",
              "0     box     251    384  67.686012  155.361250       65.4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>4. With API Docs vs Without API Docs</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>include_api_docs</th>\n",
              "      <th>passed</th>\n",
              "      <th>total</th>\n",
              "      <th>avg_score</th>\n",
              "      <th>avg_time</th>\n",
              "      <th>pass_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Without Docs</td>\n",
              "      <td>246</td>\n",
              "      <td>392</td>\n",
              "      <td>65.524781</td>\n",
              "      <td>164.777985</td>\n",
              "      <td>62.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>With Docs</td>\n",
              "      <td>295</td>\n",
              "      <td>392</td>\n",
              "      <td>79.126462</td>\n",
              "      <td>122.304082</td>\n",
              "      <td>75.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  include_api_docs  passed  total  avg_score    avg_time  pass_rate\n",
              "0     Without Docs     246    392  65.524781  164.777985       62.8\n",
              "1        With Docs     295    392  79.126462  122.304082       75.3"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h4>4a. By Model: With vs Without Docs</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>docs</th>\n",
              "      <th>With Docs</th>\n",
              "      <th>Without Docs</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_short</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>deepseek-v3.2</th>\n",
              "      <td>69.4</td>\n",
              "      <td>56.1</td>\n",
              "      <td>13.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpt-5-mini</th>\n",
              "      <td>81.1</td>\n",
              "      <td>69.4</td>\n",
              "      <td>11.7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "docs           With Docs  Without Docs  Delta\n",
              "model_short                                  \n",
              "deepseek-v3.2       69.4          56.1   13.3\n",
              "gpt-5-mini          81.1          69.4   11.7"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h4>4b. By Service: With vs Without Docs</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>docs</th>\n",
              "      <th>With Docs</th>\n",
              "      <th>Without Docs</th>\n",
              "      <th>Delta</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>box</th>\n",
              "      <td>78.1</td>\n",
              "      <td>52.6</td>\n",
              "      <td>25.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>slack</th>\n",
              "      <td>72.5</td>\n",
              "      <td>72.5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "docs     With Docs  Without Docs  Delta\n",
              "service                                \n",
              "box           78.1          52.6   25.5\n",
              "slack         72.5          72.5    0.0"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h3>5. Usage Summary</h3>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total: 43,989,433 tokens | $11.6799 USD\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<h4>5a. Usage by Model</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_short</th>\n",
              "      <th>tests</th>\n",
              "      <th>tokens</th>\n",
              "      <th>cost</th>\n",
              "      <th>tokens_per_test</th>\n",
              "      <th>cost_per_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>deepseek-v3.2</td>\n",
              "      <td>392</td>\n",
              "      <td>22084278</td>\n",
              "      <td>6.151061</td>\n",
              "      <td>56337</td>\n",
              "      <td>0.0157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gpt-5-mini</td>\n",
              "      <td>392</td>\n",
              "      <td>21905155</td>\n",
              "      <td>5.528794</td>\n",
              "      <td>55880</td>\n",
              "      <td>0.0141</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     model_short  tests    tokens      cost  tokens_per_test  cost_per_test\n",
              "0  deepseek-v3.2    392  22084278  6.151061            56337         0.0157\n",
              "1     gpt-5-mini    392  21905155  5.528794            55880         0.0141"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<h4>5b. Usage by Model: With vs Without Docs</h4>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokens per test:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>docs</th>\n",
              "      <th>With Docs</th>\n",
              "      <th>Without Docs</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_short</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>deepseek-v3.2</th>\n",
              "      <td>76673</td>\n",
              "      <td>36002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpt-5-mini</th>\n",
              "      <td>71715</td>\n",
              "      <td>40046</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "docs           With Docs  Without Docs\n",
              "model_short                           \n",
              "deepseek-v3.2      76673         36002\n",
              "gpt-5-mini         71715         40046"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cost per test:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>docs</th>\n",
              "      <th>With Docs</th>\n",
              "      <th>Without Docs</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model_short</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>deepseek-v3.2</th>\n",
              "      <td>0.0211</td>\n",
              "      <td>0.0103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpt-5-mini</th>\n",
              "      <td>0.0150</td>\n",
              "      <td>0.0132</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "docs           With Docs  Without Docs\n",
              "model_short                           \n",
              "deepseek-v3.2     0.0211        0.0103\n",
              "gpt-5-mini        0.0150        0.0132"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "analyze_results(merged)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
